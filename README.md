[English](README_en.md) | **ä¸­æ–‡**

[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)

# My LLM SDK

**ä¸€å¥—ä»£ç ï¼Œè°ƒç”¨å¤šå®¶æ¨¡å‹ã€‚**

> ç”¨åŒä¸€å¥— `client.generate()` / `stream()` è°ƒç”¨ Gemini / Qwen / OpenAI-compatibleã€‚  
> å†…ç½®é¢„ç®—æ§åˆ¶ã€429 è‡ªåŠ¨ç­‰å¾…é‡è¯•ã€Ledger è®°è´¦ä¸ç”¨é‡ç»Ÿè®¡ã€‚  
> é€‚åˆï¼šå›¢é˜Ÿå…±äº«æ¨¡å‹ç­–ç•¥ + ä¸ªäººæœ¬åœ° Key éš”ç¦» + éœ€è¦ç¨³å®šè·‘æ‰¹/é«˜å¹¶å‘/æˆæœ¬å¯è¿½è¸ªçš„åœºæ™¯ã€‚

---

## ğŸš€ å¿«é€Ÿä¸Šæ‰‹

### åœ¨ä½ çš„é¡¹ç›®ä¸­ä½¿ç”¨

```bash
# 1. å®‰è£…ï¼ˆä»æœ¬åœ°è·¯å¾„ï¼Œæœªæ¥æ”¯æŒ pip install my-llm-sdkï¼‰
pip install -e <SDKè·¯å¾„>/my-llm-sdk
# ä¾‹: pip install -e ~/projects/my-llm-sdk      (macOS/Linux)
#     pip install -e C:\Users\ä½ \my-llm-sdk     (Windows)

# 2. åœ¨ä½ çš„é¡¹ç›®ç›®å½•ä¸‹åˆå§‹åŒ–é…ç½®
python -m my_llm_sdk.cli init

# 3. ç¼–è¾‘ config.yamlï¼Œå¡«å…¥ API Key

# 4. è°ƒç”¨
python -m my_llm_sdk.cli generate --model gemini-2.5-flash --prompt "ä½ å¥½"
```

### å‚ä¸ SDK å¼€å‘

```bash
git clone https://github.com/NoneSeniorEngineer/my-llm-sdk.git
cd my-llm-sdk
pip install -e .
python -m my_llm_sdk.cli doctor
```

---

## ğŸ’¡ ä¸ºä»€ä¹ˆç”¨å®ƒ

| éœ€æ±‚ | My LLM SDK çš„è§£å†³æ–¹æ¡ˆ |
| :--- | :--- |
| **ä¸€æ¬¡æ¥å…¥ï¼Œå¤šå®¶åˆ‡æ¢** | ä¸æ”¹ä»£ç ï¼Œåªæ¢ `model_alias` |
| **æ€•è´¦å•å¤±æ§** | è¯·æ±‚å‰é¢„ç®—æ£€æŸ¥ + ç»Ÿä¸€ Ledger è®°è´¦ |
| **æ€• 429 / è¶…æ—¶** | è‡ªåŠ¨é€€é¿é‡è¯•ï¼Œå¯é…ç½®æœ€å¤§ç­‰å¾… |
| **å›¢é˜Ÿåä½œ** | `llm.project.yaml` (Git) + `config.yaml` (æœ¬åœ°) å½»åº•åˆ†ç¦» |
| **è·‘æ‰¹ / å¹¶å‘** | Async + Streaming + ç»“æ„åŒ–è¿”å›ï¼ˆcost/token ç»Ÿä¸€ï¼‰ |

---

## ğŸ§ª å…¸å‹ç”¨æ³•

### 1. è·‘æ‰¹ï¼šé¢„ç®—å°é¡¶ + è‡ªåŠ¨é‡è¯•
é€‚åˆ nightly job / æ•°æ®æ ‡æ³¨ / è¯„æµ‹è„šæœ¬ï¼šè¶…é¢„ç®—è‡ªåŠ¨æ‹’ç»ï¼Œ429 è‡ªåŠ¨ç­‰å¾…é‡è¯•ã€‚

### 2. åœ¨çº¿æœåŠ¡ï¼šStreaming + ç»Ÿä¸€ç”¨é‡ç»Ÿè®¡
`stream=True` æµå¼è¿”å›ï¼ŒåŒæ—¶ç²¾ç¡®è®°å½• token/cost åˆ° Ledgerã€‚

### 3. å›¢é˜Ÿåä½œï¼šç­–ç•¥å…±äº«ï¼ŒKey æ°¸ä¸å…¥åº“
`llm.project.yaml` æäº¤åˆ° Gitï¼›`config.yaml` åªåœ¨æœ¬åœ°ï¼ˆæ”¯æŒ personal overridesï¼‰ã€‚

---

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

| åŠŸèƒ½ | è¯´æ˜ |
| :--- | :--- |
| **ç»Ÿä¸€æ¥å£** | ä¸€å¥— `client.generate()` è°ƒç”¨æ‰€æœ‰å‚å•† |
| **å¤šæ¨¡å‹æ”¯æŒ** | Gemini 2.5/3.0, Qwen Max/Plus/Flash, OpenAI Compatible |
| **å¤šæ¨¡æ€ (V0.4)** | å›¾ç‰‡ç”Ÿæˆã€è¯­éŸ³åˆæˆ (TTS)ã€è¯­éŸ³è¯†åˆ« (ASR)ã€Vision ç†è§£ |
| **Async + Streaming** | `generate_async` / `stream_async` æ”¯æŒé«˜å¹¶å‘ |
| **ç»“æ„åŒ–è¿”å›** | `full_response=True` è·å– usage/cost/token |
| **é¢„ç®—æ§åˆ¶** | æ¯æ¬¡è¯·æ±‚å‰æ£€æŸ¥æ¶ˆè´¹ï¼Œè¶…é¢è‡ªåŠ¨æ‹’ç» |
| **å¤šæ¨¡æ€è®¡è´¹** | æŒ‰å›¾ç‰‡/éŸ³é¢‘æ—¶é•¿/TTS å­—ç¬¦æ•°ç²¾å‡†è®¡è´¹ |
| **æŠ¥è¡¨ä¸è¶‹åŠ¿** | `llm budget` å‘½ä»¤æŸ¥çœ‹æ¶ˆè€—è¶‹åŠ¿ã€æ’è¡Œå’Œä»Šæ—¥çŠ¶æ€ |
| **è‡ªåŠ¨é‡è¯•** | 429/è¶…æ—¶é€€é¿é‡è¯•ï¼Œå¯é…ç½® `max_retries` / `max_delay_s` |
| **åŒå±‚é…ç½®** | é¡¹ç›®è§„åˆ™ vs API Key åˆ†ç¦»ï¼Œé˜²æ­¢è¯¯æäº¤ |

---

## ğŸ’° å®šä»·ä¸æˆæœ¬å‚è€ƒ

SDK çš„è®¡è´¹é€»è¾‘ä»¥ `llm.project.yaml` ä¸­çš„é…ç½®ä¸ºå‡†ã€‚é»˜è®¤æ¨¡æ¿å·²å¯¹é½ä»¥ä¸‹å®˜æ–¹å…¬å¼€ä»·ï¼š

- **Google Gemini**: [Gemini API Pricing](https://ai.google.dev/gemini-api/docs/pricing)
- **Alibaba Qwen**: [Alibaba Cloud Model Pricing](https://www.alibabacloud.com/help/en/model-studio/model-pricing?spm=a2c63.p38356.help-menu-2400256.d_0_0_3.5b933fd9UZWrpM)

| å¹³å°/åŒºåŸŸ | è®¡è´¹å£å¾„ | æ ¸å¿ƒå·®å¼‚ |
| :--- | :--- | :--- |
| **Qwen (Mainland)** | çº¦ $0.345/1M (Max) | ğŸš€ ä»·æ ¼æä½ï¼Œé€‚åˆå›½å†…å¤‡æ¡ˆä¸šåŠ¡ï¼Œå®‰å…¨è¿‡æ»¤è¾ƒä¸¥ |
| **Qwen (International)** | çº¦ $1.6/1M (Max) | ğŸŒ æ–°åŠ å¡/å…¨çƒèŠ‚ç‚¹ï¼Œå¯¹æ ‡ GPT-4 é€»è¾‘ï¼Œè¿‡æ»¤è¾ƒæ¾ |
| **Gemini (Standard)** | $0.075 - $1.25 / 1M | âš¡ é˜¶æ¢¯è®¡è´¹ï¼Œ>128k/200k ä¸Šä¸‹æ–‡ä»·æ ¼ç¿»å€ |

> **æç¤º**ï¼šè¯·æ ¹æ®éƒ¨ç½²ç¯å¢ƒåœ¨ `llm.project.yaml` ä¸­å¾®è°ƒä»·æ ¼ã€‚ç›®å‰ SDK é»˜è®¤é‡‡ç”¨ä¿å®ˆçš„å›½é™…ç‰ˆ/åŸºç¡€æ¡£å®šä»·ã€‚

---

## âœ… å¯é æ€§

- **è‡ªåŠ¨é‡è¯•**ï¼š429/è¶…æ—¶é€€é¿ï¼ˆå¯é…ç½®æœ€å¤§æ¬¡æ•°ä¸æœ€å¤§ç­‰å¾…æ—¶é—´ï¼‰
- **Ledger è®°è´¦**ï¼šæ¯æ¬¡è¯·æ±‚è®°å½• cost / token / provider / model / latency
- **ç»“æ„åŒ–è¿”å›**ï¼š`full_response=True` ç»Ÿä¸€æ‹¿åˆ° usage/cost
- **æµ‹è¯•è¦†ç›–**ï¼š`pytest` å•å…ƒæµ‹è¯• + ç«¯åˆ°ç«¯éªŒè¯è„šæœ¬

---

## ğŸ“¦ Python API

```python
from my_llm_sdk.client import LLMClient
from my_llm_sdk.schemas import GenConfig, TaskType, ContentPart

client = LLMClient()

# åŸºç¡€è°ƒç”¨
response = client.generate("ä½ å¥½", model_alias="gemini-2.5-flash")
print(response)

# ç»“æ„åŒ–å¯¹è±¡ï¼ˆå« cost/tokenï¼‰
res = client.generate("ä½ å¥½", full_response=True)
print(f"Cost: ${res.cost}, Tokens: {res.usage.total_tokens}")

# æµå¼è¾“å‡º
for event in client.stream("æ•°åˆ°5", model_alias="qwen-max"):
    print(event.delta, end="", flush=True)

# --- V0.4.0 å¤šæ¨¡æ€ç¤ºä¾‹ ---

# å›¾ç‰‡ç”Ÿæˆ
# å›¾ç‰‡ç”Ÿæˆ (V0.4.1 å¢å¼º)
from PIL import Image

# åœºæ™¯ 1: çº¯æ–‡ç”Ÿå›¾ (Text-to-Image)
res = client.generate(
    "A cyberpunk city street at night, neon lights, rain, highly detailed",
    model_alias="gemini-3-pro-image-preview",
    config={
        "image_size": "2K",       # å¯é€‰: 1K (é»˜è®¤), 2K, 4K (ä»… Pro)
        "aspect_ratio": "16:9"    # å¯é€‰: 1:1, 16:9, 4:5, 3:4, 21:9 ç­‰
    },
    full_response=True
)

# ğŸ’¡ å‚æ•°å‚è€ƒ (Gemini 3 Pro)
# | æ¯”ä¾‹  | 1K åˆ†è¾¨ç‡   | 2K åˆ†è¾¨ç‡   | 4K åˆ†è¾¨ç‡   |
# | :--- | :--- | :--- | :--- |
# | 1:1  | 1024x1024 | 2048x2048 | 4096x4096 |
# | 16:9 | 1376x768  | 2752x1536 | 5504x3072 |
# | 4:5  | 928x1152  | 1856x2304 | 3712x4608 |
# æ›´å¤šè¯¦æƒ…: https://ai.google.dev/gemini-api/docs/image-generation?hl=zh-cn

# åœºæ™¯ 2: å›¾ç”Ÿå›¾ / æ··åˆè¾“å…¥ (Image-to-Image / Mixed Input)
# list ä¸­å¯æ··åˆ: å­—ç¬¦ä¸² prompt, PIL.Image å¯¹è±¡, æˆ– ContentPart
res = client.generate(
    model_alias="gemini-3-pro-image-preview",
    contents=[
         "Convert this sketch into a photorealistic portrait.", 
         Image.open("sketch.png") 
    ],
    full_response=True
)

# --- å…³é”®: é€šè¿‡ TEXT å†…å®¹æ’æŸ¥é—®é¢˜ ---
# å›¾ç‰‡ç”Ÿæˆæ—¶ï¼ŒGoogle ä¾ç„¶ä¼šè¿”å› TEXTã€‚
# 1. æˆåŠŸæ—¶: TEXT é€šå¸¸æ˜¯ "Here is the image..." (æ— ç”¨ä¿¡æ¯)
# 2. å¤±è´¥æ—¶: TEXT åŒ…å«ç”±äºç‰ˆæƒ/æš´åŠ›/çœŸäººç­‰åŸå› è¢«æ‹¦æˆªçš„ *å…·ä½“è¯´æ˜* (å…³é”® Debug ä¿¡æ¯)

if res.finish_reason == "safety_blocked":
    # Case A: å®‰å…¨æ‹¦æˆª (æ— å›¾ç‰‡)
    print(f"ğŸ›‘ ç”Ÿæˆè¢«æ‹¦æˆª! åŸå› : {res.content}") 
    #ä¾‹å¦‚: "I cannot create images of specific real people."
    
elif res.media_parts:
    # Case B: æˆåŠŸç”Ÿæˆ
    print(f"âœ… ç”ŸæˆæˆåŠŸ! å¼•å¯¼è¯­: {res.content}")
    print(f"å›¾ç‰‡å·²ä¿å­˜è‡³: {res.media_parts[0].local_path}")
    
else:
    # Case C: å…¶ä»–å¼‚å¸¸
    print(f"âš ï¸ ç”Ÿæˆç»“æŸä½†æ— å›¾ç‰‡ï¼Œè¯·æ£€æŸ¥ Promptã€‚æ¨¡å‹å›å¤: {res.content}")

# è¯­éŸ³åˆæˆ (TTS)
res = client.generate(
    "ä½ å¥½ï¼Œæˆ‘æ˜¯è¯­éŸ³åŠ©æ‰‹ã€‚",
    model_alias="qwen-tts-realtime",
    config=GenConfig(
        task=TaskType.TTS,
        voice_config={"voice_name": "your-voice-id"}
    ),
    full_response=True
)
print(f"Audio saved to: {res.media_parts[0].local_path}")

# è¯­éŸ³è¯†åˆ« (ASR)
with open("audio.wav", "rb") as f:
    audio_data = f.read()
res = client.generate(
    model_alias="qwen3-asr-flash",
    contents=[ContentPart(type="audio", inline_data=audio_data, mime_type="audio/wav")],
    config=GenConfig(task=TaskType.ASR),
    full_response=True
)
print(f"Transcription: {res.content}")
```

# --- V0.6.0 Volcengine (Doubao) ç¤ºä¾‹ ---

# 1. æ·±åº¦æ€è€ƒ (Doubao-Thinking)
# æ”¯æŒå¤šæ¨¡æ€è¾“å…¥ (å›¾ç‰‡ + æ–‡æœ¬)
res = client.generate(
    model_alias="doubao-thinking", 
    contents=[
        ContentPart(type="image", file_uri="local_image.jpg"),
        "è¿™å¼ å›¾é‡Œæœ‰ä»€ä¹ˆï¼Ÿè¯¦ç»†åˆ†æã€‚"
    ],
    config={"thought_mode": "low"}, # æ€è€ƒæ¨¡å¼: low / middle / high
    full_response=True
)
print(res.content)

# 2. DeepSeek R1 / V3
# è‡ªåŠ¨è·¯ç”±è‡³ç«å±±å¼•æ“ Ark Runtime
res = client.generate(
    "å¦‚ä½•å®ç°å¿«é€Ÿæ’åºï¼Ÿ",
    model_alias="deepseek-v3",
    full_response=True
)

# 3. è§†é¢‘ç”Ÿæˆ (Seedance)
# è‡ªåŠ¨å¤„ç†ä»»åŠ¡åˆ›å»ºä¸è½®è¯¢
res = client.generate(
    model_alias="doubao-video",
    prompt="æ— äººæœºä»¥æå¿«é€Ÿåº¦ç©¿è¶Šæ£®æ—ï¼Œ4kç”»è´¨",
    config={
        "task": TaskType.VIDEO_GENERATION,
        "resolution": "1080p", # 720p / 1080p
        "duration": 5          # 3 / 5 / 10 ç§’
    },
    full_response=True
)
print(f"Video URL: {res.media_parts[0].file_uri}")
```

---

## ğŸ”§ é…ç½®å‚è€ƒ

### config.yamlï¼ˆæœ¬åœ°ï¼Œå‹¿æäº¤ Gitï¼‰
```yaml
api_keys:
  google: "AIzaSy..."
  dashscope: "sk-..."
daily_spend_limit: 5.0
```

### llm.project.yamlï¼ˆå¯æäº¤ Gitï¼‰
```yaml
model_registry:
  gemini-2.5-flash:
    provider: google
    model_id: gemini-2.5-flash
    rpm: 1000
```

### é‡è¯•é…ç½®
```yaml
resilience:
  max_retries: 3
  wait_on_rate_limit: true
  max_delay_s: 60
```

### æœ¬åœ°æ¨¡å‹è¦†ç›–ï¼ˆå¦‚ Ollamaï¼‰
```yaml
personal_model_overrides:
  llama-3-local:
    provider: openai
    model_id: llama3
    api_base: "http://localhost:11434/v1"
    api_base: "http://localhost:11434/v1"
```

### ç½‘ç»œé…ç½® (V0.6+)
é’ˆå¯¹å›½å†…ç¯å¢ƒä¼˜åŒ–ï¼šå¼€å¯ VPN å…¨å±€ä»£ç†æ—¶ï¼Œè‡ªåŠ¨ç»•è¿‡ç³»ç»Ÿä»£ç†ç›´è¿å›½å†…æ¨¡å‹ï¼ˆQwen/Doubaoï¼‰ï¼Œé™ä½å»¶è¿Ÿã€‚

> **é…ç½®ä½ç½®**ï¼š
> - **ä¸ªäººç”Ÿæ•ˆ**ï¼š`config.yaml` (æ¨èï¼Œä¸å½±å“ä»–äºº)
> - **é¡¹ç›®ç”Ÿæ•ˆ**ï¼š`llm.project.yaml` (å›¢é˜Ÿç»Ÿä¸€ç­–ç•¥)

```yaml
network:
  # æ€»å¼€å…³ï¼šæ˜¯å¦å¯ç”¨ç›´è¿ä¼˜åŒ–ï¼ˆé»˜è®¤ Trueï¼‰
  proxy_bypass_enabled: true
  
  # éœ€è¦ç›´è¿çš„ Provider åˆ—è¡¨
  bypass_proxy:
    - alibaba      # é€šä¹‰åƒé—® (DashScope)
    - dashscope    # åˆ«å
    - volcengine   # å­—èŠ‚è±†åŒ…
    - baidu        # æ–‡å¿ƒä¸€è¨€
    - zhipu        # æ™ºè°± GLM

### è‡ªå®šä¹‰ API Endpoint (V0.6+)
å¦‚æœæ‚¨éœ€è¦è¦†ç›–é»˜è®¤çš„å‚å•† API åœ°å€ï¼ˆä¾‹å¦‚ä½¿ç”¨è‡ªå»ºä»£ç†æˆ–å†…ç½‘åœ°å€ï¼‰ï¼Œè¯·åœ¨ `config.yaml` çš„ `endpoints` åˆ—è¡¨ä¸­æ·»åŠ ï¼š

```yaml
endpoints:
  # è¦†ç›–ç«å±±å¼•æ“é»˜è®¤åœ°å€ (name = provider_name)
  - name: "volcengine"
    url: "https://ark.cn-beijing.volces.com/api/v3"
    region: "cn-beijing"

  # è¦†ç›– OpenAI åœ°å€
  - name: "openai"
    url: "https://my-proxy.com/v1"
    region: "us"
```
```

---

## ğŸ“Š CLI é¢„ç®—ä¸æŠ¥è¡¨ (V0.5+)

SDK å†…ç½®äº†å¼ºå¤§çš„ç”¨é‡ç»Ÿè®¡ä¸é¢„ç®—ç®¡ç†å·¥å…·ã€‚

### 1. ä»Šæ—¥æ¶ˆè€—çŠ¶æ€
```bash
python -m my_llm_sdk.cli budget status
```
å±•ç¤ºä»Šæ—¥å·²ç”¨é‡‘é¢ã€è¯·æ±‚æ•°ã€Token æ•°ä»¥åŠé¢„ç®—è¿›åº¦æ¡ã€‚

### 2. æ¶ˆè€—è¶‹åŠ¿å›¾
```bash
python -m my_llm_sdk.cli budget report --days 7
```
ä½¿ç”¨æŸ±çŠ¶å›¾å±•ç¤ºæœ€è¿‘ N å¤©çš„è´¹ç”¨æ”¯å‡ºè¶‹åŠ¿ã€‚

### 3. æ¶ˆè€—å¤§æˆ·æ’è¡Œ
```bash
python -m my_llm_sdk.cli budget top --by model
```
æŒ‰æ¨¡å‹æˆ–å‚å•†å¯¹æ”¯å‡ºè¿›è¡Œæ’åºï¼Œæ‰¾å‡ºâ€œæœ€è´µâ€çš„è°ƒç”¨æ¥æºã€‚

---

## ğŸ“Š æ€§èƒ½åŸºå‡† (2025-12)

| æ¨¡å‹ | ç®€å•ä»»åŠ¡ | å¤æ‚ä»»åŠ¡ | å›ç­”é•¿åº¦ | ç‰¹ç‚¹ |
| :--- | :--- | :--- | :--- | :--- |
| qwen-flash | **3.70s** | 48.53s | 11414c | å“åº”æœ€å¿« |
| gemini-3.0-flash | 4.49s | **14.85s** | 5403c | å¤æ‚ä»»åŠ¡æœ€å¿« |
| qwen-plus | 3.95s | 33.15s | 7968c | ç®€å•ä»»åŠ¡æå¿« |
| gemini-2.5-pro | 16.47s | 53.80s | 9988c | æ·±åº¦æ€è€ƒ |
| qwen-max | 9.75s | 31.36s | 3822c | å›ç­”ç²¾ç‚¼ |

> **å¤ç°**ï¼š`python benchmark.py` (å¼€å‘æ¨¡å¼ä¸‹è¿è¡Œ)  
> **ç¯å¢ƒ**ï¼šmacOS + å®¶ç”¨ç½‘ç»œï¼Œä¸åŒåœ°åŒº/ç½‘ç»œå·®å¼‚å¤§  
> **ä»»åŠ¡å®šä¹‰**ï¼šSimple = å¸¸è¯†é—®ç­”ï¼›Complex = å¤šçº¿ç¨‹çˆ¬è™«ä»£ç ç”Ÿæˆ

---

## ğŸ—ºï¸ Roadmap

- [x] æ ¸å¿ƒç®¡æ§ä¸é¢„ç®—æ‹¦æˆª (V0.1)
- [x] ç»“æ„åŒ–å“åº”ä¸ Streaming (V0.2)
- [x] Async å…¨é“¾è·¯æ”¯æŒ (V0.3)
- [x] è¿ç»´æŠ¥è¡¨ä¸ CLI å·¥å…· (V0.5.0)
- [x] V0.5.x: ç²¾å‡†è®¡è´¹ä¸æµæ°´é‡è®¡ç®— (V0.5.1)
- [x] V0.5.x: é¢„ç®—æ¯”ä¾‹é¢„è­¦ä¸ç¡¬æ€§ç†”æ–­ (V0.5.2)
- [x] V0.5.x: è‡ªåŠ¨åŒ–æµ‹è¯•å¥—ä»¶ (Pytest Integration, V0.5.3)
- [x] V0.5.4: Gemini å®˜æ–¹ SDK å‡çº§ (`google-genai`)
- [x] V0.4.0: å¤šæ¨¡æ€æ”¯æŒ (Vision / TTS / ASR / Image Gen)
- [ ] å‘å¸ƒåˆ° PyPI (`pip install my-llm-sdk`)

---

## ğŸ¤ è´¡çŒ®

1. Fork æœ¬ä»“åº“
2. åœ¨ `src/my_llm_sdk/providers/` æ·»åŠ æ–° Providerï¼ˆç»§æ‰¿ `BaseProvider`ï¼‰
3. åœ¨ `src/my_llm_sdk/client.py` çš„ `self.providers` ä¸­æ³¨å†Œ
4. æäº¤ PR

---

## ğŸ“„ License

[Apache 2.0](LICENSE)
